{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thejan/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# just for the sake of this blog post!\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'dataset'\n",
    "X = pd.read_csv(filepath + '/dengue_features_train.csv')\n",
    "Y = pd.read_csv(filepath + '/dengue_labels_train.csv')\n",
    "T = pd.read_csv(filepath + '/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function  Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function,\n",
    "    1. inputs a dataframe\n",
    "    2. encodes categorical column \"city\"\n",
    "    3. concats it to the dataframe\n",
    "    4. drops unwanted columns ['year','weekofyear','week_start_date','city']\n",
    "    5. fills NaN values\n",
    "    6. normalizes the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess1(data):\n",
    "    # y['city']=y['city'].map({'iq':1,'sj':0})  Ordinal\n",
    "    \n",
    "    # X = X.interpolate()\n",
    "    \n",
    "    # X[X.columns] = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # encodes \"city column\"\n",
    "    city_features = pd.get_dummies(data['city'], prefix='city_')\n",
    "    # concats city_features to data\n",
    "    data = pd.concat([city_features, data], axis=1)\n",
    "    # drops columns\n",
    "    dropping_columns = ['year','weekofyear','week_start_date','city']\n",
    "    data = data.drop(dropping_columns, axis=1)\n",
    "    # fills NaN values\n",
    "    data.fillna(method='ffill', inplace=True) #bfill\n",
    "    # normalize\n",
    "    data[data.columns] = MinMaxScaler().fit_transform(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function,\n",
    "    1. inputs a dataframe - train\n",
    "    2. drop columns having more than 10% NaN values\n",
    "    3. fills NaN values - interpolate\n",
    "    4. seperate city data\n",
    "    5. drops unwanted columns ['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train(data):\n",
    "    # fill NaN values\n",
    "    data.interpolate(inplace=True)\n",
    "    # seperate into two cities\n",
    "    data_sj = data[data['city'] == \"sj\"]\n",
    "    data_iq = data[data['city'] == \"iq\"]\n",
    "    # drop columns\n",
    "    dropping_columns = ['city']\n",
    "    data_sj = data_sj.drop(dropping_columns, axis=1)\n",
    "    data_iq = data_iq.drop(dropping_columns, axis=1)\n",
    "    \n",
    "    \n",
    "    return X_sj, X_iq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropColumns(train,test):\n",
    "    # drop columns having more than 10% NaN values\n",
    "    NaNDic = (train.isnull().sum()*100/train.shape[0])>=10\n",
    "    for i in train.columns.values:\n",
    "        if(NaNDic[i]):\n",
    "            train.drop(i,axis=1,inplace=True)\n",
    "            test.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] >= threshold:\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot HeatMap of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotHeatMap(dataset):\n",
    "    f,ax = plt.subplots(figsize=(18, 18))\n",
    "    sn.heatmap(dataset.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                                     0.000000\n",
       "year                                     0.000000\n",
       "weekofyear                               0.000000\n",
       "week_start_date                          0.000000\n",
       "ndvi_ne                                  2.953297\n",
       "ndvi_nw                                  0.755495\n",
       "ndvi_se                                  0.068681\n",
       "ndvi_sw                                  0.068681\n",
       "precipitation_amt_mm                     0.137363\n",
       "reanalysis_air_temp_k                    0.137363\n",
       "reanalysis_avg_temp_k                    0.137363\n",
       "reanalysis_dew_point_temp_k              0.137363\n",
       "reanalysis_max_air_temp_k                0.137363\n",
       "reanalysis_min_air_temp_k                0.137363\n",
       "reanalysis_precip_amt_kg_per_m2          0.137363\n",
       "reanalysis_relative_humidity_percent     0.137363\n",
       "reanalysis_sat_precip_amt_mm             0.137363\n",
       "reanalysis_specific_humidity_g_per_kg    0.137363\n",
       "reanalysis_tdtr_k                        0.137363\n",
       "station_avg_temp_c                       0.824176\n",
       "station_diur_temp_rng_c                  0.824176\n",
       "station_max_temp_c                       0.206044\n",
       "station_min_temp_c                       0.618132\n",
       "station_precip_mm                        0.343407\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((T.isnull().sum()*100/X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
